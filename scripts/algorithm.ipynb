{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "65a9aef5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Matplotlib is building the font cache; this may take a moment.\n"
     ]
    }
   ],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re, ast\n",
    "from scipy.sparse import csr_matrix, hstack, vstack, issparse\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a724aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded! Shape: (4624615, 9)\n",
      " Columns: ['parent_asin', 'price', 'product_title', 'categories', 'rating', 'user_id', 'review_title', 'text', 'merged_text']\n",
      " Unique books: 137,249\n",
      " Unique users: 2,766,656\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/prep.csv')\n",
    "print(f\" Loaded! Shape: {df.shape}\")\n",
    "print(f\" Columns: {df.columns.tolist()}\")\n",
    "print(f\" Unique books: {df['parent_asin'].nunique():,}\")\n",
    "print(f\" Unique users: {df['user_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "11fcc7e8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_items(df):\n",
    "\n",
    "    print(\"Extracting unique items and building metadata table...\\n\")\n",
    "\n",
    "    # Validate required columns\n",
    "    required_columns = ['parent_asin', 'price', 'rating', 'merged_text']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing required column: {col}\")\n",
    "\n",
    "    # Aggregate at the item level\n",
    "    item_df = (\n",
    "        df.groupby('parent_asin')\n",
    "        .agg(\n",
    "            price = ('price', 'first'),\n",
    "            avg_rating = ('rating', 'mean'),\n",
    "            num_ratings = ('rating', 'count'),\n",
    "            text = ('merged_text', 'first'),\n",
    "        )\n",
    "    ).reset_index()\n",
    "\n",
    "    # Display summary and preview\n",
    "    print(f\"Extracted {item_df.shape[0]:,} unique items.\")\n",
    "    print(\"Preview of item metadata:\")\n",
    "    print(item_df.head())\n",
    "\n",
    "    return item_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "dc15c00a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting unique items and building metadata table...\n",
      "\n",
      "Extracted 137,249 unique items.\n",
      "Preview of item metadata:\n",
      "  parent_asin  price  avg_rating  num_ratings  \\\n",
      "0  0007922582     51    2.000000            1   \n",
      "1  0008288194     14    3.000000            1   \n",
      "2  0028179714     15    4.666667            3   \n",
      "3  0060501960      8    4.470588           17   \n",
      "4  0063052164     20    5.000000            4   \n",
      "\n",
      "                                                text  \n",
      "0  The Sneetches and Other Stories [] Too small w...  \n",
      "1  The Creativity Code ['Video Games', 'PC', 'Gam...  \n",
      "2  The Autobiography of Miss Jane Pittman and Rel...  \n",
      "3  Presidents' Day ['Video Games', 'PC', 'Games']...  \n",
      "4  Stranger Planet AUTOGRAPHED / SIGNED BOOK ['Vi...  \n"
     ]
    }
   ],
   "source": [
    "item_df = extract_unique_items(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "9a53178d",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_item_representation(df, max_features=10000, min_df=2, ngram_range=(1,2)):\n",
    "\n",
    "    print(\"Building hybrid item representations (text + numeric)...\\n\")\n",
    "\n",
    "    # TF-IDF vectorization for textual metadata\n",
    "    tfidf = TfidfVectorizer(max_features=max_features, min_df=min_df, ngram_range=ngram_range, stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(item_df['text'])\n",
    "\n",
    "    # Select and normalize numeric features\n",
    "    numeric_features = ['price', 'avg_rating', 'num_ratings']\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Convert to numeric safely\n",
    "    numeric_data = df[numeric_features].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "    numeric_scaled = scaler.fit_transform(numeric_data)\n",
    "    print(f\"Numeric features scaled (columns: {numeric_features})\")\n",
    "\n",
    "    # Convert to sparse format for concatenation\n",
    "    numeric_sparse = np.nan_to_num(numeric_scaled)\n",
    "\n",
    "    # Concatenate text and numeric representations\n",
    "    hybrid_matrix = hstack([tfidf_matrix, numeric_sparse]).tocsr()\n",
    "    print(f\"Final hybrid matrix shape: {hybrid_matrix.shape}\")\n",
    "\n",
    "    # Maintain item lookup for interpretation\n",
    "    tfidf_index = df[\"parent_asin\"].reset_index(drop=True)\n",
    "    print(\"Created lookup table linking vectors to item parent_asin.\\n\")\n",
    "    print(tfidf_index.head())\n",
    "\n",
    "    return hybrid_matrix, tfidf, tfidf_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cc8b6327",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Building hybrid item representations (text + numeric)...\n",
      "\n",
      "Numeric features scaled (columns: ['price', 'avg_rating', 'num_ratings'])\n",
      "Final hybrid matrix shape: (137249, 10003)\n",
      "Created lookup table linking vectors to item parent_asin.\n",
      "\n",
      "0    0007922582\n",
      "1    0008288194\n",
      "2    0028179714\n",
      "3    0060501960\n",
      "4    0063052164\n",
      "Name: parent_asin, dtype: object\n"
     ]
    }
   ],
   "source": [
    "hybrid_matrix, tfidf, tfidf_index = build_item_representation(item_df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2041857f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nuser_vector = np.zeros(embedding_dim)\\ntotal_weight = 0\\n\\nfor review in user_reviews:\\n    idx = tfidf_index[tfidf_index == review['parent_asin']].index[0]\\n    item_vec = hybrid_matrix[idx]\\n    weight = review['rating']\\n\\n    user_vector += weight * item_vec\\n    total_weight += weight\\n\\nuser_vector /= total_weight\\nsims = cosine_similarity(user_vector.reshape(1, -1), hybrid_matrix)[0]\\n\""
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# receive an user... A user hopefully contains a list of reviews with ratings, or just a thumbs up and down.\n",
    "\n",
    "# flask POST request gives us a list of parent_asins and the associated ratinsg\n",
    "# Can't fully read it, but it eems like if the user doesn't rate, its not in the post request.\n",
    "\n",
    "# test example for now:\n",
    "user_reviews = [\n",
    "    {'parent_asin': 'B00069EVOG', 'rating': 5},\n",
    "    {'parent_asin': 'B00002S9MH', 'rating': 3},\n",
    "    {'parent_asin': 'B000FH0MHO', 'rating': 4},\n",
    "]\n",
    "\n",
    "def return_recommended_items(user_reviews, tfidf_index, hybrid_matrix, top_k = 10, top_n=10):\n",
    "    # two dictionaries: one to store weighted scores, and a total similairty sum, so I can normalize later\n",
    "    # both are keyed by item_index : val\n",
    "    scores = {}      \n",
    "    sim_sums = {}\n",
    "    \n",
    "    # For each review the user has given:\n",
    "    for review in user_reviews:\n",
    "        parent_asin = review['parent_asin']\n",
    "        rating = review['rating']\n",
    "        \n",
    "        # Double check validity\n",
    "        if parent_asin in tfidf_index.values:\n",
    "\n",
    "            # Get the row index of the item in the hybird matrix, then compute cosine similarity\n",
    "            row_idx = tfidf_index[tfidf_index == parent_asin].index[0]\n",
    "            sims = cosine_similarity(hybrid_matrix[row_idx], hybrid_matrix)[0]\n",
    "\n",
    "            # Top_k determines how many similar items to consider for each item the user has rated\n",
    "            # runtime gets longer for higher k vals, we can disscuss val later\n",
    "            k = top_k\n",
    "            \n",
    "            # Get the indices of the top k similar items\n",
    "            top_k_idx = np.argpartition(sims, -k)[-k:]\n",
    "            top_k_idx = top_k_idx[np.argsort(sims[top_k_idx])[::-1]]\n",
    "            top_k_sims = sims[top_k_idx]\n",
    "\n",
    "\n",
    "            # calculate those similarity scores\n",
    "            # formula I use is user rating of current item * similarity score\n",
    "            for neighbor_idx, sim_val in zip(top_k_idx, top_k_sims):\n",
    "\n",
    "                # Exclude self-similarity\n",
    "                if neighbor_idx == row_idx:\n",
    "                    continue\n",
    "                weight = rating * sim_val\n",
    "                scores[neighbor_idx] = scores.get(neighbor_idx, 0) + weight\n",
    "                sim_sums[neighbor_idx] = sim_sums.get(neighbor_idx, 0) + abs(sim_val)\n",
    "\n",
    "    # sort our scores, and also normalize. \n",
    "    # This normalzation order was given to me by ChatGPT, we can disscuss validly later.\n",
    "    ranked_scores = {idx: score / sim_sums[idx] for idx, score in scores.items()}\n",
    "    ranked_items = sorted(ranked_scores.items(), key=lambda x: x[1], reverse=True)\n",
    "\n",
    "    # Now, just return the top_n items, excluding any the user has already reviewed\n",
    "    recommended_items = []\n",
    "    amount_to_return = top_n\n",
    "    for idx, score in ranked_items[:top_n]:\n",
    "        if tfidf_index[idx] not in [review['parent_asin'] for review in user_reviews]:\n",
    "            recommended_items.append((tfidf_index[idx], float(score)))\n",
    "        else:\n",
    "            amount_to_return += 1\n",
    "            \n",
    "    return recommended_items\n",
    "\n",
    "\n",
    "# TODO:\n",
    "# find a way to tie these parent_asins \n",
    "# back to the title of the products, maybe need to keep title as part of prep_df\n",
    "\n",
    "# TODO:prep\n",
    "# create a user embedding and see if thats better. \n",
    "'''\n",
    "user_vector = np.zeros(embedding_dim)\n",
    "total_weight = 0\n",
    "\n",
    "for review in user_reviews:\n",
    "    idx = tfidf_index[tfidf_index == review['parent_asin']].index[0]\n",
    "    item_vec = hybrid_matrix[idx]\n",
    "    weight = review['rating']\n",
    "    \n",
    "    user_vector += weight * item_vec\n",
    "    total_weight += weight\n",
    "\n",
    "user_vector /= total_weight\n",
    "sims = cosine_similarity(user_vector.reshape(1, -1), hybrid_matrix)[0]\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "680c776f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('B0002MHF2C', 5.0),\n",
       " ('B005CWFVJQ', 5.0),\n",
       " ('B00005OUIW', 5.0),\n",
       " ('B09ZXZH48T', 5.0),\n",
       " ('B01LYST149', 5.0),\n",
       " ('B0000E2XEG', 5.0),\n",
       " ('B0009QVE6O', 5.0),\n",
       " ('B000VJG6VM', 5.0),\n",
       " ('B0085Z8V5I', 5.0),\n",
       " ('4591153320', 4.0)]"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "return_recommended_items(user_reviews, tfidf_index, hybrid_matrix, top_k=10, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "59a042a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "user_reviews = {'parent_asin': 'B007X47EK0', 'rating': 5, 'parent_asin': 'B004A7FOIC', 'rating': 5},\n",
    "recommended_items = return_recommended_items(user_reviews, tfidf_index, hybrid_matrix, top_k=10, top_n=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "5a796b15",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "  parent_asin  score  price  avg_rating  num_ratings  \\\n",
      "0  B07NVTR5FD    5.0     22    4.333333           57   \n",
      "1  B07HM9N443    5.0     19    4.352941           17   \n",
      "2  B076CZJWWW    5.0     20    5.000000            1   \n",
      "3  B000PDY2JW    5.0     28    5.000000            1   \n",
      "4  B000VWRH80    5.0     27    5.000000            1   \n",
      "5  B078QC63NX    5.0     24    4.513514           37   \n",
      "6  B01M63WQUQ    5.0     25    5.000000            2   \n",
      "7  B018LDDZN6    5.0     25    5.000000            1   \n",
      "8  B018JPBOG6    5.0     28    5.000000            4   \n",
      "\n",
      "                                                text  \n",
      "0  Star Wars Battlefront II - Xbox One ['Video Ga...  \n",
      "1  Star Wars Battlefront - Xbox (Renewed) ['Video...  \n",
      "2  Star Wars Battlefront II 2100 Crystals - Xbox ...  \n",
      "3  Star Wars Battlefront - Xbox ['Video Games', '...  \n",
      "4  Star Wars Battlefront: Renegade Squadron (PSP)...  \n",
      "5  Star Wars Battlefront II PS4 ['Video Games', '...  \n",
      "6  EA Star Wars Battlefront (Xbox One) with Exclu...  \n",
      "7  PlayStation 4 500GB Console - Star Wars Battle...  \n",
      "8  PS4 EA Star Wars Battlefront Exclusive Trading...  \n"
     ]
    }
   ],
   "source": [
    "def get_items_details(recommended_items, item_df):\n",
    "    # Convert recommended items to DataFrame\n",
    "    rec_df = pd.DataFrame(recommended_items, columns=['parent_asin', 'score'])\n",
    "    \n",
    "    # Merge with item_df to get details\n",
    "    detailed_rec_df = rec_df.merge(item_df, on='parent_asin', how='left')\n",
    "    \n",
    "    return detailed_rec_df\n",
    "\n",
    "detailed_recommendations = get_items_details(recommended_items, item_df)\n",
    "print(detailed_recommendations)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f484cd67",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5434c09b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "info376",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.14"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
