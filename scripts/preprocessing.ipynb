{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "65a9aef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import re, ast\n",
    "from scipy.sparse import csr_matrix, hstack, vstack, issparse\n",
    "\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, HashingVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from sklearn.manifold import TSNE\n",
    "from sklearn.decomposition import PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a724aeb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Loaded! Shape: (4624615, 5)\n",
      " Columns: ['parent_asin', 'price', 'rating', 'user_id', 'merged_text']\n",
      " Unique books: 137,249\n",
      " Unique users: 2,766,656\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv('../data/prep.csv')\n",
    "print(f\" Loaded! Shape: {df.shape}\")\n",
    "print(f\" Columns: {df.columns.tolist()}\")\n",
    "print(f\" Unique books: {df['parent_asin'].nunique():,}\")\n",
    "print(f\" Unique users: {df['user_id'].nunique():,}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cfaa668e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_unique_items(df):\n",
    "\n",
    "    print(\"Extracting unique items and building metadata table...\\n\")\n",
    "\n",
    "    # Validate required columns\n",
    "    required_columns = ['parent_asin', 'price', 'rating', 'merged_text']\n",
    "    for col in required_columns:\n",
    "        if col not in df.columns:\n",
    "            raise ValueError(f\"Missing required column: {col}\")\n",
    "\n",
    "    # Aggregate at the item level\n",
    "    item_df = (\n",
    "        df.groupby('parent_asin')\n",
    "        .agg(\n",
    "            price = ('price', 'first'),\n",
    "            avg_rating = ('rating', 'mean'),\n",
    "            num_ratings = ('rating', 'count'),\n",
    "            text = ('merged_text', 'first'),\n",
    "        )\n",
    "    ).reset_index()\n",
    "\n",
    "    # Display summary and preview\n",
    "    print(f\"Extracted {item_df.shape[0]:,} unique items.\")\n",
    "    print(\"Preview of item metadata:\")\n",
    "    print(item_df.head())\n",
    "\n",
    "    return item_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "11fcc7e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting unique items and building metadata table...\n",
      "\n",
      "Extracted 137,249 unique items.\n",
      "Preview of item metadata:\n",
      "  parent_asin  price  avg_rating  num_ratings  \\\n",
      "0  0007922582     51    2.000000            1   \n",
      "1  0008288194     14    3.000000            1   \n",
      "2  0028179714     15    4.666667            3   \n",
      "3  0060501960      8    4.470588           17   \n",
      "4  0063052164     20    5.000000            4   \n",
      "\n",
      "                                                text  \n",
      "0  The Sneetches and Other Stories    Too small w...  \n",
      "1  The Creativity Code   Video Games    PC    Gam...  \n",
      "2  The Autobiography of Miss Jane Pittman and Rel...  \n",
      "3  Presidents  Day   Video Games    PC    Games  ...  \n",
      "4  Stranger Planet AUTOGRAPHED   SIGNED BOOK   Vi...  \n"
     ]
    }
   ],
   "source": [
    "item_df = extract_unique_items(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "75ab526b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_item_representation(df, max_features=10000, min_df=2, ngram_range=(1,2)):\n",
    "\n",
    "    print(\"Building hybrid item representations (text + numeric)...\\n\")\n",
    "\n",
    "    # TF-IDF vectorization for textual metadata\n",
    "    tfidf = TfidfVectorizer(max_features=max_features, min_df=min_df, ngram_range=ngram_range, stop_words='english')\n",
    "    tfidf_matrix = tfidf.fit_transform(item_df['text'])\n",
    "\n",
    "    # Select and normalize numeric features\n",
    "    numeric_features = ['price', 'avg_rating', 'num_ratings']\n",
    "    scaler = StandardScaler()\n",
    "\n",
    "    # Convert to numeric safely\n",
    "    numeric_data = df[numeric_features].apply(pd.to_numeric, errors=\"coerce\").fillna(0)\n",
    "    numeric_scaled = scaler.fit_transform(numeric_data)\n",
    "    print(f\"Numeric features scaled (columns: {numeric_features})\")\n",
    "\n",
    "    # Convert to sparse format for concatenation\n",
    "    numeric_sparse = np.nan_to_num(numeric_scaled)\n",
    "\n",
    "    # Concatenate text and numeric representations\n",
    "    hybrid_matrix = hstack([tfidf_matrix, numeric_sparse])\n",
    "    print(f\"Final hybrid matrix shape: {hybrid_matrix.shape}\")\n",
    "\n",
    "    # Maintain item lookup for interpretation\n",
    "    tfidf_index = df[\"parent_asin\"].reset_index(drop=True)\n",
    "    print(\"Created lookup table linking vectors to book titles.\\n\")\n",
    "\n",
    "    return hybrid_matrix, tfidf, tfidf_index"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "amazonrecommender",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
